{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6gs1l01SSEBZ"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.get_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mNA5potptZ8Z"
   },
   "outputs": [],
   "source": [
    "!pip install simpletransformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x0jGAV0fR6WP"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZJt222DcR6WT"
   },
   "outputs": [],
   "source": [
    "food_df = pd.read_csv(\"food_training_df.csv\")\n",
    "food_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h1Kex013R6Wa"
   },
   "outputs": [],
   "source": [
    "food_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JYpZ6u_XR6Wc"
   },
   "outputs": [],
   "source": [
    "food_df['Topic'] = food_df['Topic'].replace(to_replace=['Food Effect', 'Non Food Effect'], value = [1,0]).astype(float)\n",
    "food_df[['Topic', 'Data_Source']].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G8mAMOMUR6Wl"
   },
   "source": [
    "##### Split into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x7_8nyHLs1Gw"
   },
   "outputs": [],
   "source": [
    "dm_food_df = food_df[food_df['Data_Source'] == 'DailyMed'].sample(n = 1200, random_state = 1234)\n",
    "df_food_df = food_df[food_df['Data_Source'] == 'DrugsFDA'].sample(n = 1200, random_state = 1234)\n",
    "print(dm_food_df['Topic'].value_counts())\n",
    "print(df_food_df['Topic'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jx-_Wkj_tRE0"
   },
   "outputs": [],
   "source": [
    "def prepare_data(df):\n",
    "    train_df = df.sample(frac = 0.8, random_state = 1234)\n",
    "    test_df = df.drop(train_df.index).reset_index(drop=True)\n",
    "    train_df = train_df.reset_index(drop = True)\n",
    "    print('{},{}'.format(str(len(train_df)), str(len(test_df))))\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HsiWyF38tU2S"
   },
   "outputs": [],
   "source": [
    "dm_train_df, dm_test_df = prepare_data(dm_food_df)\n",
    "print(dm_train_df['Topic'].value_counts())\n",
    "print(dm_test_df['Topic'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vgeU-kQCtXI-"
   },
   "outputs": [],
   "source": [
    "df_train_df, df_test_df = prepare_data(df_food_df)\n",
    "print(df_train_df['Topic'].value_counts())\n",
    "print(df_test_df['Topic'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b21O_56_tZ0f"
   },
   "outputs": [],
   "source": [
    "dmdf_train_df = pd.concat([dm_train_df, df_train_df])\n",
    "print(dmdf_train_df['Topic'].value_counts())\n",
    "dmdf_test_df = pd.concat([dm_test_df, df_test_df])\n",
    "print(dmdf_test_df['Topic'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6G5ewDiER6Wp"
   },
   "outputs": [],
   "source": [
    "from simpletransformers.classification import ClassificationModel\n",
    "from sklearn.metrics import f1_score, accuracy_score, roc_auc_score, recall_score, precision_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l5A3VBajR6Ws"
   },
   "source": [
    "###### Set the arguments and train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "073msVd3R6Wt"
   },
   "outputs": [],
   "source": [
    "train_args = {\n",
    "   'output_dir': 'outputs/',\n",
    "   'cache_dir': 'cache/',\n",
    "   'max_seq_length': 100,\n",
    "   'train_batch_size': 32,\n",
    "   'eval_batch_size': 8,\n",
    "   'gradient_accumulation_steps': 1,\n",
    "   'num_train_epochs': 1,\n",
    "   'weight_decay': 0,\n",
    "   'learning_rate': 4e-5,\n",
    "   'adam_epsilon': 1e-8,\n",
    "   'warmup_ratio': 0.06,\n",
    "   'warmup_steps': 0,\n",
    "   'max_grad_norm': 1.0,\n",
    "   'logging_steps': 50,\n",
    "   'evaluate_during_training': False,\n",
    "   'save_steps': 2000,\n",
    "   'eval_all_checkpoints': True,\n",
    "   'use_tensorboard': True,\n",
    "   'overwrite_output_dir': True,\n",
    "   'reprocess_input_data': True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZzgJusiuR6Wv"
   },
   "outputs": [],
   "source": [
    "dmdf_train_df = dmdf_train_df[['Paragraph', 'Topic']]\n",
    "dmdf_test_df = dmdf_test_df[['Paragraph', 'Topic']]\n",
    "dmdf_train_df['Paragraph'] = dmdf_train_df['Paragraph'].str.lower()\n",
    "dmdf_test_df['Paragraph'] = dmdf_test_df['Paragraph'].str.lower()\n",
    "dmdf_test_df.head()\n",
    "print(dmdf_train_df['Topic'].value_counts())\n",
    "print(dmdf_test_df['Topic'].value_counts())\n",
    "\n",
    "dm_train_df = dm_train_df[['Paragraph', 'Topic']]\n",
    "dm_test_df = dm_test_df[['Paragraph', 'Topic']]\n",
    "dm_train_df['Paragraph'] = dm_train_df['Paragraph'].str.lower()\n",
    "dm_test_df['Paragraph'] = dm_test_df['Paragraph'].str.lower()\n",
    "print(dm_train_df['Topic'].value_counts())\n",
    "print(dm_test_df['Topic'].value_counts())\n",
    "\n",
    "df_train_df = df_train_df[['Paragraph', 'Topic']]\n",
    "df_test_df = df_test_df[['Paragraph', 'Topic']]\n",
    "df_train_df['Paragraph'] = df_train_df['Paragraph'].str.lower()\n",
    "df_test_df['Paragraph'] = df_test_df['Paragraph'].str.lower()\n",
    "print(df_train_df['Topic'].value_counts())\n",
    "print(df_test_df['Topic'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z-akVV8JZYuS",
    "outputId": "1f2d48a3-9753-4019-a250-ccbeee40b472"
   },
   "outputs": [],
   "source": [
    "# Install apex makes use_cuda=1 works much faster\n",
    "%%writefile setup.sh\n",
    "\n",
    "git clone https://github.com/NVIDIA/apex\n",
    "cd apex\n",
    "pip install -v --no-cache-dir ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m9kbBf3BZc3k"
   },
   "outputs": [],
   "source": [
    "!sh setup.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HsGCkBwcR6W9"
   },
   "source": [
    "#### Define a simple function to calculate (using sklearn.metrics) evaluation measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tJ6FVSd5R6W-"
   },
   "outputs": [],
   "source": [
    "def report_results(A, B):\n",
    "    A_name = A.name\n",
    "    B_name = B.name\n",
    "    \n",
    "    df = pd.DataFrame({'A':A,\n",
    "                       'B':B})\n",
    "    df = df.dropna()\n",
    "    A = df['A']\n",
    "    B = df['B']\n",
    "    \n",
    "    acc = accuracy_score(B, A)\n",
    "    f1 = f1_score(B, A)\n",
    "    prec = precision_score(B, A)\n",
    "    rec = recall_score(B, A)\n",
    "    ROC = roc_auc_score(B, A)\n",
    "    \n",
    "    print('Candidate: '+A_name+' | Ground Truth: '+B_name+'\\n')\n",
    "    print('accuracy: %0.2f \\nprecision: %0.2f \\nrecall: %0.2f \\nF1 score: %0.2f \\nROC AUC: %0.2f \\n' % (acc, prec, rec, f1, ROC))\n",
    "    return prec, rec, f1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k6Eb3_ukuHZd"
   },
   "outputs": [],
   "source": [
    "data_source_result_df = pd.DataFrame(columns=['F1'])\n",
    "method_result_df = pd.DataFrame(columns=['Precision', 'Recall', 'F1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3IFuZJwLDA3N"
   },
   "outputs": [],
   "source": [
    "!rm -rf runs cache/ outputs/ cache_dir/\n",
    "model_bert = ClassificationModel('bert', 'bert-base-uncased', args=train_args)\n",
    "model_bert.train_model(dmdf_train_df)\n",
    "result, model_outputs, wrong_predictions = model_bert.eval_model(dmdf_test_df, acc=accuracy_score)\n",
    "dmdf_test_df['BERT_topic'] = np.argmax(model_outputs, axis = 1)\n",
    "prec, rec, f1 = report_results(dmdf_test_df['BERT_topic'], dmdf_test_df['Topic'])\n",
    "method_result_df.loc['bert-base-uncased'] = [prec, rec, f1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EnuPeYMCig5z"
   },
   "outputs": [],
   "source": [
    "!rm -rf runs cache/ outputs/ cache_dir/\n",
    "model_roberta = ClassificationModel('roberta', 'roberta-base', args=train_args)\n",
    "model_roberta.train_model(dmdf_train_df)\n",
    "result, model_outputs, wrong_predictions = model_roberta.eval_model(dmdf_test_df, acc=accuracy_score)\n",
    "dmdf_test_df['roberta_topic'] = np.argmax(model_outputs, axis = 1)\n",
    "prec, rec, f1 = report_results(dmdf_test_df['roberta_topic'], dmdf_test_df['Topic'])\n",
    "method_result_df.loc['roberta-base'] = [prec, rec, f1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yTFXMJpVwEvE"
   },
   "outputs": [],
   "source": [
    "!rm -rf runs cache/ outputs/ cache_dir/\n",
    "model_distilbert = ClassificationModel('distilbert', 'distilbert-base-uncased', args=train_args)\n",
    "model_distilbert.train_model(dmdf_train_df)\n",
    "result, model_outputs, wrong_predictions = model_distilbert.eval_model(dmdf_test_df, acc=accuracy_score)\n",
    "dmdf_test_df['distilbert_topic'] = np.argmax(model_outputs, axis = 1)\n",
    "prec, rec, f1 = report_results(dmdf_test_df['distilbert_topic'], dmdf_test_df['Topic'])\n",
    "data_source_result_df.loc['dm+df_dm+df'] = [f1]\n",
    "method_result_df.loc['distilbert-base-uncased'] = [prec, rec, f1]\n",
    "\n",
    "!rm -rf runs cache/ outputs/ cache_dir/\n",
    "model_distilbert.train_model(dm_train_df)\n",
    "result, model_outputs, wrong_predictions = model_distilbert.eval_model(dmdf_test_df, acc=accuracy_score)\n",
    "dmdf_test_df['distilbert_topic'] = np.argmax(model_outputs, axis = 1)\n",
    "prec, rec, f1 = prec, rec, f1 = report_results(dmdf_test_df['distilbert_topic'], dmdf_test_df['Topic'])\n",
    "data_source_result_df.loc['dm_dm+df'] = [f1]\n",
    "\n",
    "!rm -rf runs cache/ outputs/ cache_dir/\n",
    "model_distilbert.train_model(df_train_df)\n",
    "result, model_outputs, wrong_predictions = model_distilbert.eval_model(dmdf_test_df, acc=accuracy_score)\n",
    "dmdf_test_df['distilbert_topic'] = np.argmax(model_outputs, axis = 1)\n",
    "prec, rec, f1 = prec, rec, f1 = report_results(dmdf_test_df['distilbert_topic'], dmdf_test_df['Topic'])\n",
    "data_source_result_df.loc['df_dm+df'] = [f1]\n",
    "\n",
    "\n",
    "!rm -rf runs cache/ outputs/ cache_dir/\n",
    "model_distilbert.train_model(dmdf_train_df)\n",
    "result, model_outputs, wrong_predictions = model_distilbert.eval_model(dm_test_df, acc=accuracy_score)\n",
    "dm_test_df['distilbert_topic'] = np.argmax(model_outputs, axis = 1)\n",
    "prec, rec, f1 = report_results(dm_test_df['distilbert_topic'], dm_test_df['Topic'])\n",
    "data_source_result_df.loc['dm+df_dm'] = [f1]\n",
    "\n",
    "!rm -rf runs cache/ outputs/ cache_dir/\n",
    "model_distilbert.train_model(dm_train_df)\n",
    "result, model_outputs, wrong_predictions = model_distilbert.eval_model(dm_test_df, acc=accuracy_score)\n",
    "dm_test_df['distilbert_topic'] = np.argmax(model_outputs, axis = 1)\n",
    "prec, rec, f1 = report_results(dm_test_df['distilbert_topic'], dm_test_df['Topic'])\n",
    "data_source_result_df.loc['dm_dm'] = [f1]\n",
    "\n",
    "!rm -rf runs cache/ outputs/ cache_dir/\n",
    "model_distilbert.train_model(df_train_df)\n",
    "result, model_outputs, wrong_predictions = model_distilbert.eval_model(dm_test_df, acc=accuracy_score)\n",
    "dm_test_df['distilbert_topic'] = np.argmax(model_outputs, axis = 1)\n",
    "prec, rec, f1 = report_results(dm_test_df['distilbert_topic'], dm_test_df['Topic'])\n",
    "data_source_result_df.loc['df_dm'] = [f1]\n",
    "\n",
    "\n",
    "!rm -rf runs cache/ outputs/ cache_dir/\n",
    "model_distilbert.train_model(dmdf_train_df)\n",
    "result, model_outputs, wrong_predictions = model_distilbert.eval_model(df_test_df, acc=accuracy_score)\n",
    "df_test_df['distilbert_topic'] = np.argmax(model_outputs, axis = 1)\n",
    "prec, rec, f1 = report_results(df_test_df['distilbert_topic'], df_test_df['Topic'])\n",
    "data_source_result_df.loc['dm+df_df'] = [f1]\n",
    "\n",
    "!rm -rf runs cache/ outputs/ cache_dir/\n",
    "model_distilbert.train_model(dm_train_df)\n",
    "result, model_outputs, wrong_predictions = model_distilbert.eval_model(df_test_df, acc=accuracy_score)\n",
    "df_test_df['distilbert_topic'] = np.argmax(model_outputs, axis = 1)\n",
    "prec, rec, f1 = report_results(df_test_df['distilbert_topic'], df_test_df['Topic'])\n",
    "data_source_result_df.loc['dm_df'] = [f1]\n",
    "\n",
    "!rm -rf runs cache/ outputs/ cache_dir/\n",
    "model_distilbert.train_model(df_train_df)\n",
    "result, model_outputs, wrong_predictions = model_distilbert.eval_model(df_test_df, acc=accuracy_score)\n",
    "df_test_df['distilbert_topic'] = np.argmax(model_outputs, axis = 1)\n",
    "prec, rec, f1 = report_results(df_test_df['distilbert_topic'], df_test_df['Topic'])\n",
    "data_source_result_df.loc['df_df'] = [f1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nwd_3nw97hyL"
   },
   "outputs": [],
   "source": [
    "data_source_result_df.to_csv('data_source_result_df_bert.csv', index=True)\n",
    "method_result_df.to_csv('method_result_df_bert.csv', index=True)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "food_model_bert.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
